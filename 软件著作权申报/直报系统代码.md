# 利用在线问卷综合收集问卷数据与文档资料的辅助系统

## 代码总体说明

目前常用的在线问卷系统不仅可以收集问卷信息，还可以接受用户上传的文档材料，而问卷的管理人员可以在后台分别下载问卷数据以及附件压缩包。尽管在问卷数据中，存储了指向附件的网络链接，但这些链接要通过一定的步骤才能转换成指向本地附件文件的链接。本软件包括两部分，分别协助进行1. 数据文件和附件的下载，2. 将网络链接转换成本地链接。

代码文件：
1. `selenium_start.py` 自动化
2. `feiyong_parse.py` 提供`FeiyongParser`类
3. `mazui_feiyong.py`提供`LinZhuFeiyongParser`类
4. `xl2zb_conv.py`将`hisBA1parser.py`输出的中间文件转化成广东省卫生健康统计信息网络直报系统能够读取的xlsx文件

## hisBA1parser.py代码


```python
import xml.etree.ElementTree as ET
import os,re
from datetime import date, datetime
import pandas as pd
import numpy as np
import snoop
import pyperclip

bl_csv = "ht_tbs_record.csv"
ndns_csv = "ndns.csv"

# from unjoined_fp_ndns import JoinedCsvSplitter
from feiyong_parse import FeiyongParser
from mazui_feiyong import LinZhuFeiyongParser
# from zb_conv import ZBConverter

class XmlParserBase(object):
    parameterFile = os.path.join('xmlFiles', 'para.xlsx')
    xl = pd.ExcelFile(parameterFile)
    df_HIS_BA1 = xl.parse("HIS_BA1",dtype=str).set_index('field')
    df_HIS_BA4 = xl.parse("HIS_BA4",dtype=str).set_index('field')
    df_linzhu_coder = xl.parse("临嘱coder",dtype=str)
    df_coder_coll = xl.parse('coder_coll',dtype=str).set_index('coder')
    srs_field2coder = xl.parse('field2coder',dtype=str).set_index('field')
    reDigit = re.compile(r'^[\d\.]*$')
    reBirthIDCard = re.compile(r'\d{6}(\d{4})(\d{2})(\d{2})[0-9A-Za-z]{4}')
    reBirthDay = re.compile(r'(\d{4})[\-年](\d{1,2})[\-月](\d{1,2})日?')
    reIrregDate = re.compile(r'(\d{4})[\-年\/]?(\d{1,2})[\-月\/]?(\d{1,2})日?')
    reAddrProvinces = re.compile(r"""
                    \d*(
                    北京市|天津市|上海市|重庆市|
                    北京|天津|上海|重庆|
                    内蒙古自治区|西藏自治区|宁夏回族自治区|新疆维吾尔自治区|
                    西藏|宁夏|新疆|内蒙古|
                    台湾省|台湾|香港特别行政区|香港|澳门特别行政区|澳门|
                    .*省|
                    河北|山西|辽宁|吉林|黑龙江|江苏|浙江|安徽|福建|江西|山东|河南|湖北|湖南|
                    广东|海南|四川|贵州|云南|陕西|甘肃|青海|
                    广西壮族自治区|广西                
                    )
                """, re.VERBOSE)
    reAddrRegular = re.compile(r"""
            (.*市)
            (.*[市区县])
            (.*)
        """,re.VERBOSE)
    reAddrFoshanShi = re.compile(r"佛山市?")
    reAddrDistric = re.compile(r"""
                (禅城区?|南海区?|顺德区?|高明区?|三水区?)
                (.*)
            """, re.VERBOSE)
    reEmptyNode = re.compile(r'^\s+$|\s*无\s*|^$')

class XmlParserColl(XmlParserBase):
    def __init__(self,srs_csv_raw:pd.core.series.Series):
        """
        获取一个FCONTENT的series，建立coll类
        :param df_csv_raw:外部传入ht.tbl首页数据读取的df，将FPATNO设置为index
        """
        super(XmlParserColl, self).__init__()
        self.srs_csv_raw = srs_csv_raw

    def fcontent_parser_gen(self,xml_element:ET.Element,fpatno:int=0):
        return FCONTENTParser(xml_element,fpatno)

    def gen_fcnt_psrs(self):
        return self.srs_csv_raw.apply(
            lambda fcnt: self.fcontent_parser_gen(ET.fromstring(fcnt))
        )

    def parse_csv_raw_BA1(self):
        df_csv_raw = self.srs_csv_raw.reset_index()
        df_csv_raw['FPATNO'] = df_csv_raw['FPATNO'].astype(int)
        df_csv_raw['id']=df_csv_raw['FPATNO']
        df_csv_raw = df_csv_raw.set_index('id')
        return df_csv_raw.apply(
            lambda row:self.fcontent_parser_gen(ET.fromstring(row['FCONTENT']),row['FPATNO']).parse_FCONTENT(),
            axis=1
        )

    def parse_csv_raw_BA3(self):
        df_csv_raw = self.srs_csv_raw.reset_index()
        df_csv_raw['FPATNO'] = df_csv_raw['FPATNO'].astype(int)
        df_csv_raw['id']=df_csv_raw['FPATNO']
        df_csv_raw = df_csv_raw.set_index('id')
        srs_df_BA3 = df_csv_raw.apply(
            lambda row:self.fcontent_parser_gen(ET.fromstring(row['FCONTENT']),row['FPATNO']).diag_gen(),
            axis=1
        )

        list_BA3 = list(srs_df_BA3)
        return pd.concat(list_BA3).reset_index().drop('index',axis=1)

    def parse_csv_raw_BA4(self):
        df_csv_raw = self.srs_csv_raw.reset_index()
        df_csv_raw['FPATNO'] = df_csv_raw['FPATNO'].astype(int)
        df_csv_raw['id']=df_csv_raw['FPATNO']
        df_csv_raw = df_csv_raw.set_index('id')
        srs_df_BA4 = df_csv_raw.apply(
            lambda row:self.fcontent_parser_gen(ET.fromstring(row['FCONTENT']),row['FPATNO']).surg_gen(),
            axis=1
        )
        list_BA4 = list(srs_df_BA4)
        return pd.concat(list_BA4).reset_index().drop('index',axis=1)

class FCONTENTParser(XmlParserBase):
    def __init__(self, xml_element:ET.Element,fpatno:int=0):
        super(FCONTENTParser, self).__init__()
        self.fpatno = fpatno
        self.function_dict = {
            "dateParser":self.dateParser,
            "birthDayParser": self.birthDayParser,
            "coder":self.coder,
            "pathoFH":self.pathoFH,
            "zkrqParser":self.zkrqParser,
            "nowaddrParser":self.nowaddrParser,
            "comaCalc":self.comaCalc,
            "ageParser":self.ageParser,
            "surgIF": self.surgIF,
            "irreg_date_parser":self.irreg_date_parser,
            "fsum":self.fsum,
            "jiguan_coder":self.jiguan_coder,
        }
        self.root = xml_element

    def parse_FCONTENT(self):
        # 这个类还需要被继承，所以就把判断新版首页的代码放在parse_FCONTENT里面，这个函数后面也要override
        if self.we_think_it_is_empty(self.root.find("./FirstPageNew1")):
            raise Exception(self.get_patient_desc("旧版病案首页没有准备好"))
        df_HIS_BA1 = self.df_HIS_BA1.apply(
            lambda row:self.router4paras(row),
            axis=1
        )
        df_HIS_BA1['FPATNO']=self.fpatno

        return df_HIS_BA1

    def log_err(self,msg):
        with open('logfile.txt','a',encoding='gbk') as logfile:
            logfile.write(msg)

    def get_patient_desc(self,msg=""):
        patfileno = self.root.find('./eprhead/PATFILENO').text
        patname = self.root.find('./eprhead/PATNAME').text
        datein = self.root.find('./eprhead/DATEIN').text
        return f"{patfileno}: {patname}, admited in {datein}:{msg}\n"


    def get_text_from_tag(self,tag):
        node4field = self.root.find(tag)
        if node4field is None:
            raise Exception('无法找到{}对应的node'.format(tag))
        txt4field = node4field.text


        if self.we_think_it_is_empty(txt4field) or re.match(self.reEmptyNode,txt4field):
            return np.nan
        else:
            return txt4field

    def get_text_from_node(self,para_row,parse_option:int=None):
        """

        :param para_row: para.xlsx中HIS_BA1的某一列，含有相关的各种信息
        :param parse_option:如果为None，函数返回数组，如果为-1，函数返回非空值里面最长的那个,如果是其他小于len（tags）的参数，返回对应的tag
        :return:list or str
        """

        tags = [e.strip() for e in para_row['xmlTag'].split(',')]
        tags = [self.get_text_from_tag(e) for e in tags]
        if set(tags) == set([np.nan]):
            pass
            # snoop.pp(self.get_patient_desc(f"{para_row['desc']}内容为空"))
        if parse_option is None:
            return tags
        elif parse_option == -1:
            # 保留非空值里面最长的那个
            length = 0
            rst = None
            for e in set(tags):
                if pd.notna(e) and e is not None and len(str(e))>length:
                    rst = e
                    length=len(str(e))
            return rst
        elif parse_option<len(tags):
            return tags[parse_option]



    def router4paras(self,para_row):
        ftype = para_row['ftype']
        if ftype == 'mapper':
            return self.get_text_from_node(para_row,-1)
        elif ftype == 'func':
            return self.function_router(para_row)
        else:
            return para_row['para']

    def function_router(self,para_row):
        func = self.function_dict[para_row['func_name']]
        return func(para_row)

    def get_para_row(self,row_field_name):
        if row_field_name in self.df_HIS_BA1.index:
            return self.df_HIS_BA1.loc[row_field_name]
        else:
            raise Exception(f"df_HIS_BA1不包含{row_field_name}")


    def dateParser(self,para_row):
        datestr = self.get_text_from_node(para_row,-1)
        date_obj = datetime.fromisoformat(datestr)
        para = para_row['para']
        if para == "full":
            return date_obj
        elif para == "date":
            return date_obj.date()
        elif para == "time":
            return date_obj.time().hour
        elif para == "year_month":
            return f"{date_obj.year}{date_obj.month:02}"


    def irreg_date_parser(self,para_row):
        datestr = self.get_text_from_node(para_row,-1)
        year_int,month_int,day_int = [int(e) for e in re.match(self.reIrregDate,datestr).groups()]
        return date(year_int,month_int,day_int)



    # @snoop
    def birthDayParser(self,para_row):
        birthday_candidate_data = {
            'idcard':self.get_text_from_node(para_row,0),
            'birthday':self.get_text_from_node(para_row,1),
        }
        if pd.notna(birthday_candidate_data['idcard']):
            mo = re.match(self.reBirthIDCard,birthday_candidate_data['idcard'])
            if mo:
                return date.fromisoformat(f"{mo.group(1)}-{mo.group(2)}-{mo.group(3)}")
            else:
                raise Exception(self.get_patient_desc(f"idcard:{birthday_candidate_data['idcard']}内容不对"))
        else:
            mo_birthday = re.match(self.reBirthDay,birthday_candidate_data['birthday'])
            bdyear = int(mo_birthday.group(1))
            bdmonth = int(mo_birthday.group(2))
            bdday = int(mo_birthday.group(3))
            return date(bdyear,bdmonth,bdday)


    def coder(self,para_row):
        # 现在有一个问题，data_src为空值/None/pd.isna的时候，没办法用dict来映射
        # 所以这个时候还是要用df.loc[,]比较合适
        data_src = self.get_text_from_node(para_row,-1)
        if self.we_think_it_is_empty(data_src):
            data_src = np.nan
        elif type(data_src) == str:
            data_src = data_src.strip()
        para = para_row['para']
        field = para_row.name
        coder_name = self.srs_field2coder.loc[field,'coder']
        df_coder = self.df_coder_coll.loc[coder_name,]
        # ori_code,key,new_code
        # c2c,k2c,c2k
        if para=="c2c":
            df_coder = df_coder.set_index('ori_code')
            return df_coder.loc[data_src,'new_code']

        elif para == "k2c":
            df_coder = df_coder.set_index('key')
            return df_coder.loc[data_src, 'new_code']
            #
            # dict_coder = pd.Series(
            #     df_coder['new_code'].values,
            #     index=df_coder['key']
            # ).to_dict()
        elif para == "c2k":
            df_coder = df_coder.set_index('ori_code')
            return df_coder.loc[data_src, 'key']
        elif para == "k2k":
            df_coder = df_coder.set_index('key')
            return df_coder.loc[data_src,'new_key']
            # df_coder = pd.Series(
            #     df_coder['key'].values,
            #     index=df_coder['ori_code']
            # ).to_dict()
        else:
            raise Exception(f'coder only accept c2k,c2c,k2c as parameter:{para}')



    def ageParser(self,para_row):
        birthday = self.birthDayParser(self.get_para_row('FBIRTHDAY'))
        date_in = self.dateParser(self.get_para_row('FRYDATE'))
        year_diff = date_in.year-birthday.year
        month_diff= date_in.month-birthday.month
        if month_diff<0:
            year_diff = year_diff - 1
            month_diff = 0
        para = para_row['para']
        if para == "full" and year_diff>0:
            return f"Y{year_diff}"
        elif para == "full" and year_diff == 0:
            return f"M{month_diff}"
        elif para == "zb_int" and year_diff>0:
            return f"{year_diff}"
        elif para == "zb_int" and year_diff>0:
            snoop.pp(self.get_patient_desc("年龄小于1岁，年龄岁输出None"))
            return None
        elif para == "month" and year_diff == 0:
            return month_diff
        elif para == "month" and year_diff >0:
            return None

    def pathoFH(self,para_row):
        path_diag = self.get_text_from_node(para_row,0)
        para = para_row['para']
        #如果有病理诊断，返回1，符合，否则返回空值
        if para == 'outcode':
            if path_diag:
                return 1
            else:
                return None
        elif para == 'outkey':
            if path_diag:
                return "符合"
            else:
                return None


    def zkrqParser(self,para_row):
        # snoop.pp(self.get_text_from_node(para_row))
        zkrq_date = [int(e) for e in self.get_text_from_node(para_row)]
        # if len(zkrq_date) == 0:
        #     self.log_err(self.get_patient_desc("质控日期为空"))
        #     raise Exception(self.get_patient_desc(f"质控日期为空:{self.get_text_from_node(para_row)}"))
        return date(zkrq_date[0],zkrq_date[1],zkrq_date[2])
    def jiguan_coder(self,para_row):
        jiguan_addr_dict = self.nowaddr_regex_proc(para_row,prov_only=True)
    def nowaddrParser(self,para_row):
        dict_addr = self.nowaddr_regex_proc(para_row)
        para = para_row['para']
        dict_rst = {
            "本区": ["1", "医院所在区（县）"],
            "本市": ["2", "医院所在市的外区（县）"],
            "本省": ["3", "本省其他市"],
            "港澳台": ["5", "港、澳、台"],
            "其他": ["4", "外省（直辖市）"],
        }

        dict_col_index = None
        if para == "srccode":
            dict_col_index = 0
        elif para == "src":
            dict_col_index = 1

        if para == "full":
            return f"{dict_addr['省']}{dict_addr['市']}{dict_addr['区']}{dict_addr['地址']}"

        if dict_addr['区']=="禅城区" and dict_addr['市']=="佛山市":
            return dict_rst['本区'][dict_col_index]
        elif dict_addr['市']=="佛山市":
            return dict_rst['本市'][dict_col_index]
        elif dict_addr['省']=="广东省":
            return dict_rst['本省'][dict_col_index]
        elif dict_addr['省'] in ["台湾","香港特别行政区","香港","澳门"]:
            return dict_rst['港澳台'][dict_col_index]
        else:
            return dict_rst['其他'][dict_col_index]
        #     假定没有外国患者

    def nowaddr_regex_proc(self,para_row,prov_only:bool=False):
        dict_rst = {
            "省": "",
            "市": "",
            "区": "",
            "地址": "",
        }
        addr_str = self.get_text_from_node(para_row,-1)
        if self.we_think_it_is_empty(addr_str):
            raise Exception(self.get_patient_desc("现住址存在问题"))
        mo_prov = re.search(self.reAddrProvinces,addr_str)
        if mo_prov:
            dict_rst['省'] = mo_prov.group(1)
            addr_str = addr_str[mo_prov.end():]
        mo_addr_regular =re.match(self.reAddrRegular,addr_str)
        if mo_addr_regular:
            (dict_rst['市'],
             dict_rst['区'],
             dict_rst['地址']) = mo_addr_regular.groups()
            if dict_rst['市']=="佛山市":
                dict_rst['省']='广东省'

        else:
            mo_district = re.search(self.reAddrDistric,addr_str)
            if mo_district:
                dict_rst['省']='广东省'
                dict_rst['市'] = '佛山市'
                dict_rst['区'] = mo_district.group(1)
                dict_rst['地址']=mo_district.group(2)
            else:
                mo_foshan = re.search(self.reAddrFoshanShi,addr_str)
                if mo_foshan:
                    dict_rst['省'] = '广东省'
                    dict_rst['市'] = '佛山市'
                    dict_rst['区'] = ''
                    dict_rst['地址'] = addr_str
                elif prov_only:
                    pass
                else:
                    pyperclip.copy(addr_str)
                    raise Exception(self.get_patient_desc(f"从现住址({addr_str})无法推测省，市，区等信息，请在此输入符合xx省xx市xx区格式的地址信息，并联系主管医生修正首页信息"))

        return dict_rst


    def we_think_it_is_empty(self,e):
        if (e is None) or pd.isna(e)  or e == "-" or e == "" or e == "无":
            return True
        else:
            return False

    def comaCalc(self,para_row):
        def str2int(e):
            if self.we_think_it_is_empty(e):
                return 0
            else:
                return int(e)
        time_strs = [str2int(e) for e in self.get_text_from_node(para_row)]
        sum_minutes = time_strs[0]*60*24+time_strs[1]*60+time_strs[2]
        if sum_minutes<1:
            return None
        else:
            return sum_minutes


    def fsum(self,para_row):
        sum_str = self.get_text_from_node(para_row,0)
        if self.we_think_it_is_empty(sum_str):
            return None
        is_digit = re.match(self.reDigit,sum_str)
        if is_digit:
            return sum_str
        else:
            raise Exception(self.get_patient_desc(f"总费用格式不正确：{sum_str}"))

    def surgIF(self,para_row):
        surg_str = self.get_text_from_node(para_row,0)
        if surg_str:
            return 1
        else:
            return 2

    #====================

    def diag_text_get(self,node,para_setter:dict):
        dict_rst = {}
        for child in node:
            dict_rst[child.tag] = child.text
        dict_rst = dict(dict_rst,**para_setter)
        return pd.Series(dict_rst)

    def diag_gen(self):
        # FZDLX:1-主要诊断 2-其他诊断 f –附属诊断 S-损伤中毒
        mainDiagNode = self.root.find('./DiagInfor/MainDiag')
        srs_main = self.diag_text_get(mainDiagNode,{
            'FZDLX':'1',
            'FPX':1,
            'FPATNO': self.fpatno,
        })
        othDiagNodeMain = self.root.find('./DiagInfor/OthDiag')
        othDiagNodes = [e for e in othDiagNodeMain if e.find('DiagName').text]
        srs_oth_nodes = [self.diag_text_get(e,{
            'FZDLX':'2',
            'FPX':i+1,
            'FPATNO':self.fpatno,
        }) for i,e in enumerate(othDiagNodes)]

        # df_rst = pd.concat(srs_list)
        return pd.DataFrame([srs_main]+srs_oth_nodes)

    def surg_text_get(self,node):
        return node

    def surg_gen(self):
        surg_main_node = self.root.find("./SurgInfor")
        para_setter = {
            'FPATNO':self.fpatno,
        }
        surg_psrs = pd.DataFrame([SurgParser(e,para_setter,i).parse_FCONTENT() for i,e in enumerate(surg_main_node) if e.find('OperName').text])
        return surg_psrs
        # return pd.concat([srs_surgs],axis=1).T

class SurgParser(FCONTENTParser):
    def __init__(self,xml_node:ET.Element,para_setter:dict,ind):
        super(SurgParser, self).__init__(xml_node)
        self.para_setter = para_setter
        self.surg_ind = ind
        self.surg_degree = self.get_text_from_node(self.df_HIS_BA4.loc['opdegree'], -1)
        self.surg_name = self.get_text_from_node(self.df_HIS_BA4.loc['opname'], -1)
        d_added = {
            'opDegree_gen':self.opDegree_gen,
            'opZeqi_gen':self.opZeqi_gen,
        }
        self.function_dict = dict(self.function_dict,**d_added)

    def parse_FCONTENT(self):
        srs_his_ba4_local = self.df_HIS_BA4.apply(
            lambda row: self.router4paras(row),
            axis=1
        )
        for k,v in self.para_setter.items():
            srs_his_ba4_local[k]=v
        #
        srs_his_ba4_local['ind']=self.surg_ind
        return srs_his_ba4_local

    def opDegree_gen(self,para_row):
        if para_row.name==11507:
            snoop.pp(para_row)
        if pd.isna(self.surg_name):
            return None
        elif pd.isna(self.surg_degree):
            if para_row['para']=='k2c':
                return 2
            else:
                return "II"
        else:
            return self.coder(para_row)

    def opZeqi_gen(self,para_row):
        # 0:否，1：是
        if pd.isna(self.surg_name):
            return None
        else:
            return "1"


df_raw = pd.read_csv(os.path.join('csvFile',bl_csv),encoding='gbk')

srs_fcontent = df_raw.set_index('FPATNO')['FCONTENT']
index_fcontent = srs_fcontent.index

parser_coll = XmlParserColl(srs_fcontent)
df_BA1 = parser_coll.parse_csv_raw_BA1()

# 上面的df_BA1已经删掉了部分收费项目，这些接下来通过pd.concat补上

feiyong_parser = FeiyongParser(pd.read_csv(os.path.join('csvFile',ndns_csv),encoding='gbk'))
df_feiyong = feiyong_parser.get_df_feiyong_pivot().drop(columns=[np.nan])
snoop.pp(df_feiyong.index)
feiyong_ind2keep = [e for e in df_feiyong.index if e in index_fcontent]
df_feiyong_for_tbs_record = df_feiyong.loc[feiyong_ind2keep,:]

df_BA1_with_feiyong = pd.concat([df_BA1,df_feiyong_for_tbs_record],axis=1)
df_para_linzhu_coder = parser_coll.df_linzhu_coder

filepath = os.path.join('csvFile','ht.bl_tbs_advtemp.csv')
df_linzhu = pd.read_csv(filepath,encoding='gbk')
linzhu_parser = LinZhuFeiyongParser(df_linzhu,df_para_linzhu_coder)

# 手术治疗费FZLLFSSF（麻醉FZLLFMZF+手术FZLLFSSZLF）
df_BA1_with_feiyong['FZLLFMZF'] = df_BA1_with_feiyong['FPATNO'].apply(
    lambda e:linzhu_parser.fsum_calc(e,"麻醉")
)
df_BA1_with_feiyong['FZLLFSSZLF']=df_BA1_with_feiyong['FZLLFSSF']-df_BA1_with_feiyong['FZLLFMZF']
# FZLLFSSZLF


xlout = pd.ExcelWriter(f'output_{date.today()}.xlsx',engine='xlsxwriter')
df_BA1_with_feiyong.to_excel(xlout,'BA1',index_label='id')

# 轻度校验
xlerrwriter = pd.ExcelWriter(f'err_{date.today()}.xlsx',engine='xlsxwriter')
# 1. 总费用等于各项费用之和
srs_feiyong_fsum_cal_input = df_BA1_with_feiyong['FSUM1'].astype(float)\
                             -df_BA1_with_feiyong['FXYF'].astype(float)\
                             -df_BA1_with_feiyong['FZCHYF'].astype(float)\
                             -df_BA1_with_feiyong['FZDLLCF'].astype(float)\
                             -df_BA1_with_feiyong['FZDLYXF'].astype(float)\
                             -df_BA1_with_feiyong['FZDLSSSF'].astype(float)\
                             -df_BA1_with_feiyong['FZLLFFSSF'].astype(float)\
                             -df_BA1_with_feiyong['FZHFWLYLF'].astype(float)\
                             -df_BA1_with_feiyong['FZHFWLHLF'].astype(float)\
                             -df_BA1_with_feiyong['FZLLFSSF'].astype(float)

srs_feiyong_err_selector = (srs_feiyong_fsum_cal_input<0.0001) & (srs_feiyong_fsum_cal_input>-0.0001)
df_feiyong_fsum_err = df_BA1_with_feiyong[~srs_feiyong_err_selector][['FPRN','FAGE','FNAME','FRYDATE','FCYDATE','FSUM1']]
df_feiyong_fsum_err['err_val']=srs_feiyong_fsum_cal_input
if df_feiyong_fsum_err.shape[0]>0:
    df_feiyong_fsum_err.to_excel(xlerrwriter,'01 总费用不等于各项费用之和')

# 2. 住院天数=出院日-入院日, 当天出入院=1
def in_hosp_calc(in_time:datetime,out_time:datetime):
    if out_time<in_time:
        return -1
    tdelt = out_time.date()-in_time.date()
    if tdelt.days==0:
        return 1
    else:
        return tdelt.days

in_hosp_calc_rst = df_BA1_with_feiyong.apply(
    lambda row:in_hosp_calc(row['FRYDATE'],row['FCYDATE']),
    axis=1
)
in_hosp_day_selector = in_hosp_calc_rst==df_BA1_with_feiyong['FDAYS'].astype(int)
df_in_hosp_err = df_BA1_with_feiyong[~in_hosp_day_selector][['FPRN','FAGE','FNAME','FRYDATE','FCYDATE','FDAYS']]
if df_in_hosp_err.shape[0]>0:
    df_in_hosp_err.to_excel(xlerrwriter,'02 住院天数不等于出入院日期差')

# 3. 质控日期应在出院日期以后
def qc_after_discharge(qc_date,dis_date):
    return qc_date>=dis_date.date()

qc_after_discharge_err_selector = df_BA1_with_feiyong.apply(
    lambda row:qc_after_discharge(row['FZKRQ'],row['FCYDATE']),
    axis=1
)

df_qc_after_discharge_err = df_BA1_with_feiyong[~qc_after_discharge_err_selector][['FPRN','FAGE','FNAME','FRYDATE','FCYDATE','FZKRQ']]

if df_qc_after_discharge_err.shape[0]>0:
    df_qc_after_discharge_err.to_excel(xlerrwriter,'03 质控日期早于出院日期')

# 4. 离院方式 FLYFSBH 不为5的，尸检FBODYBH应该为空
# dead
leave_at_5_selector = df_BA1_with_feiyong['FLYFSBH']=='5'
# 没有尸检信息
corp_check_selector = pd.isna(df_BA1_with_feiyong['FBODYBH'])

df_corp_check_err = df_BA1_with_feiyong[(leave_at_5_selector & corp_check_selector) | (~leave_at_5_selector & ~corp_check_selector)][['FPRN','FAGE','FNAME','FRYDATE','FCYDATE','FLYFSBH','FBODYBH']]

if df_corp_check_err.shape[0]>0:
    df_corp_check_err.to_excel(xlerrwriter,'04 非死亡病人尸检不为空')

# 5. 过敏药物check
# FGMYWIFBH：有药物过敏
has_gmyw_sel = df_BA1_with_feiyong['FGMYWIFBH']==2
# FGMYW：过敏药物
gmyw_na_sel = pd.isna(df_BA1_with_feiyong['FGMYW'])

df_gmyw_err = df_BA1_with_feiyong[(has_gmyw_sel & gmyw_na_sel)|(~has_gmyw_sel & ~gmyw_na_sel)][[
    'FPRN','FAGE','FNAME','FRYDATE','FCYDATE','FGMYWIFBH','FGMYW'
]]

if df_gmyw_err.shape[0]>0:
    df_gmyw_err.to_excel(xlerrwriter,'05 是否药物过敏与过敏药物详情不一致')

# 6. 邮政编码长度校验

def post_code_len_err(e):
    if pd.isna(e) or e is None or e=="":
        return False
    elif type(e)==str and len(e)!=6:
        return True
    elif type(e)==str and len(e)==6:
        return False
    else:
        raise Exception(f"邮编{e}无法判定长度")

post_code_dw_len_err_sel = df_BA1_with_feiyong['FDWPOST'].apply(post_code_len_err)
post_code_hk_len_err_sel = df_BA1_with_feiyong['FHKPOST'].apply(post_code_len_err)
post_code_now_len_err_sel = df_BA1_with_feiyong['FCURRPOST'].apply(post_code_len_err)


df_post_code_len_err = df_BA1_with_feiyong[post_code_dw_len_err_sel | post_code_hk_len_err_sel | post_code_now_len_err_sel]
df_post_code_len_err = df_post_code_len_err[['FPRN','FAGE','FNAME','FRYDATE','FCYDATE','FDWPOST','FHKPOST','FCURRPOST',]]

if df_post_code_len_err.shape[0]>0:
    df_post_code_len_err.to_excel(xlerrwriter,'06 邮编长度不等于6')


xlerrwriter.save()

# ====BA3 and BA4 output
psrs = parser_coll.gen_fcnt_psrs()

df_BA3 = parser_coll.parse_csv_raw_BA3()
df_BA3.to_excel(xlout,'BA3',index_label='id')
df_BA4 = parser_coll.parse_csv_raw_BA4()
df_BA4.to_excel(xlout,'BA4',index_label='id')

xlout.save()
```

## feiyong_parse.py代码

```python
import os,re
from datetime import date,datetime
import pandas as pd
import numpy as np
import snoop

# df_ba1在输出以后，目前是缺少费用信息的，这个需要在其他的表格里面读取（根据fpatno）
# 所以做一个class，接受df_ba1的一个row，返回设置了费用信息的这个row

# # testing environment setup
# from unjoined_fp_ndns import JoinedCsvSplitter
# csv_raw_splitter = JoinedCsvSplitter(os.path.join('csvFile','ht.bl_tbs_record_join_ndns_fp2.csv'))
# df_feiyong = csv_raw_splitter.df_ndns

class FeiyongParser:
    def __init__(self,df_feiyong):
        """
        这个class最后要返回一个以FPATNO（JZH）为id的df，到时候和df_HIS_BA1 concat
        与之相对的df_HIS_BA1里面对应的columns应该删掉，从para.xlsx下手
        :param df_feiyong:费用数据csv表
        """
        self.df_feiyong = df_feiyong
        parameterFile = os.path.join('xmlFiles', 'para.xlsx')
        xl = pd.ExcelFile(parameterFile)
        self.df_feiyong_coder = xl.parse('feiyong_coder').set_index('code')
        self.dict_feiyong_coder = pd.Series(
            self.df_feiyong_coder['key'],
            index=self.df_feiyong_coder.index
        ).to_dict()

        self.df_feiyong['FYLB_key'] = self.df_feiyong['FYLB'].map(self.dict_feiyong_coder)
        self.riqi_selector = self.df_feiyong.apply(
            lambda row:row['RIQI']==self.newest_date_4_jzh(row['JZH']),
            axis=1
        )
        self.df_feiyong_filtered = self.df_feiyong[self.riqi_selector]
        # df_feiyong_RIQI_selector
    def newest_date_4_jzh(self,jzh):
        df_jzh_query = self.df_feiyong.query(f'JZH == {jzh}')
        dates = sorted(df_jzh_query['RIQI'].unique())
        return dates[-1]

    def get_df_feiyong_pivot(self):
        snoop.pp(self.df_feiyong_filtered.columns)
        return self.df_feiyong_filtered.pivot(
            index='JZH',
            columns='FYLB_key',
            values='JINE'
        ).fillna(0)
```

## mazui_feiyong.py代码

```python
import pandas as pd
import re
import os,snoop
filepath = os.path.join('csvFile','ht.bl_tbs_advtemp.csv')
df_linzhu = pd.read_csv(filepath,encoding='gbk')
# snoop.pp(df_linzhu.head())
# FPRICE单价,FAMOUNT数量，FSUM总价
# FYFMC 类型
# FITEMNAME 医嘱名称
# FDATESTART 医嘱时间

xl = pd.ExcelFile(os.path.join('xmlFiles', 'para.xlsx'))
df_para = xl.parse('临嘱coder')
dict_linzhu_para = pd.Series(
    df_para['类型'].values,
    index=df_para['医嘱']
).to_dict()
df_linzhu['医嘱类型']=df_linzhu['FITEMNAME'].map(dict_linzhu_para)
df_mazui_related = df_linzhu[df_linzhu['医嘱类型']=='麻醉']
# snoop.pp(df_mazui_related)

class LinZhuFeiyongParser:
    def __init__(self,df_linzhu,df_para):
        self.df_linzhu = df_linzhu
        self.df_para = df_para
        self.dict_linzhu_para = pd.Series(
            self.df_para['类型'].values,
            index=self.df_para['医嘱']
        ).to_dict()
        self.df_linzhu['医嘱类型'] = self.df_linzhu['FITEMNAME'].map(self.dict_linzhu_para)
    def get_type_related_linzhu(self,typestr):
        assert typestr in self.df_linzhu['医嘱类型'].unique()
        return self.df_linzhu[self.df_linzhu['医嘱类型']==typestr]
    def fsum_calc(self,fpatno,typestr="麻醉"):
        df_related = self.get_type_related_linzhu(typestr)
        df_fpatno_specific = df_related[df_related['FPATNO']==fpatno]
        fsums = df_fpatno_specific['FSUM'].sum()
        return fsums
```

## xl2zb_conv.py代码

```python
import pandas as pd
import numpy as np
import re,os
import datetime
from zb_conv import ZBConverter
import snoop


xl_para = pd.ExcelFile(os.path.join('xmlFiles','para.xlsx'))
df_para_zb = xl_para.parse('HIS_BA1_zb')
df_para_import_dtype = xl_para.parse('his_ba1_import_dtype')
dict_dtype_conv= {
            'str':str,
            'int':int,
            'float':float,
            'datetime':datetime.datetime,
        }
df_para_import_dtype['dtype']=df_para_import_dtype['dtype'].map(dict_dtype_conv)
dict_df_para_import_dtype=pd.Series(
    df_para_import_dtype['dtype'].values,
    index=df_para_import_dtype['field']
).to_dict()


xl = pd.ExcelFile(f'output_{datetime.date.today()}.xlsx')

df_his_BA1 = xl.parse('BA1',index='id',dtype=dict_df_para_import_dtype)
df_his_BA3 = xl.parse('BA3',index='id',dtype={'FPATNO':int})
df_his_BA4 = xl.parse('BA4',index='id',dtype={'FPATNO':int,'opdate':datetime.datetime})

class ZBConverter:
    def __init__(self,df_his_ba1,df_his_ba3,df_his_ba4):
        self.dtype_dict = {
            'str':str,
            'int':int,
            'float':float,
        }

        self.df_his_ba1 = df_his_ba1
        self.df_his_ba3 = df_his_ba3
        self.df_his_ba3_pivot = self.diag_gen()
        self.df_his_ba4 = df_his_ba4
        self.df_his_ba4_pivot = self.surg_gen()
        xl_para = pd.ExcelFile(os.path.join('xmlFiles', 'para.xlsx'))
        self.df_para_zb = xl_para.parse('HIS_BA1_zb',dtype={'para':str})
        self.df_para_pivot_coder = xl_para.parse('pivot_coder')
        self.col_order = xl_para.parse('zb_header')['header']

        self.df_para4diag = self.df_para_pivot_coder.query('coder_name=="diag"').set_index(['variable','column_name'])
        self.df_para4surg = self.df_para_pivot_coder.query('coder_name=="surg"').set_index(['variable', 'column_name'])
        self.df_rst = pd.DataFrame()


    def rename_with_mapper(self):
        df_rename_mapper = self.df_para_zb.query('ftype == "mapper"')
        dict_rename = pd.Series(
            df_rename_mapper['conv2code'].values,
            index=df_rename_mapper['field']
        ).to_dict()
        # 之前这里没有set_index，于是出现全列nan的情况……
        self.df_rst = self.df_his_ba1.rename(dict_rename,axis=1).set_index('FPATNO')

    def setter_set(self):
        df_setter = self.df_para_zb.query('ftype=="setter"')
        df_setter.apply(
            lambda row:self.setter_iteror(row),
            axis=1
        )

    def setter_iteror(self,para_row):
        self.df_rst[para_row['conv2code']] = para_row['para']



    def diag_gen(self):
        df_diag = self.df_his_ba3
        df_diag['zdlx_order']=df_diag['FZDLX']*100+df_diag['FPX']
        df_diag = df_diag.set_index(['FPATNO'])
        df_diag_piv = df_diag.pivot(columns='zdlx_order',values=['DiagName','InHospStat'])
        return df_diag_piv

    def diag_with_normal_name(self):
        self.df_para4diag.apply(lambda row:self.df_rst_set_diag_entry(row['combine'],row.name),axis=1)

    def df_rst_set_diag_entry(self,column_name,lookup_tuple):
        if lookup_tuple in self.df_his_ba3_pivot.columns:
            temp = self.df_his_ba3_pivot[lookup_tuple]
            temp = temp.rename(column_name)
            self.df_rst.loc[:,column_name]=temp
        else:
            self.df_rst.loc[:,column_name]=np.nan

    def surg_gen(self):
        df_surg = self.df_his_ba4
        df_surg_piv = df_surg.drop(columns=['id']).pivot(index='FPATNO',columns='ind')
        return df_surg_piv

    def surg_with_normal_name(self):
        self.df_para4surg.apply(lambda row:self.df_rst_set_surg_entry(row['combine'],row.name),axis=1)

    def df_rst_set_surg_entry(self,column_name,lookup_tuple):
        if lookup_tuple in self.df_his_ba4_pivot.columns:
            # hacky fix for opdate correction:
            temp = self.df_his_ba4_pivot[lookup_tuple]
            if lookup_tuple[0]=='opdate':
                snoop.pp(lookup_tuple)
                temp = temp.apply(lambda e:self.date2ymdformat(e))
            temp.rename(column_name)
            self.df_rst[column_name]=temp
        else:
            self.df_rst[column_name]=np.nan

    def date2ymdformat(self,datetime_obj):
        if pd.isna(datetime_obj):
            return ""
        else:
            return f"{datetime_obj:%Y%m%d}"




conv = ZBConverter(df_his_BA1,df_his_BA3,df_his_BA4)
conv.rename_with_mapper()
# also some hacky modification:
conv.df_rst['出生日期(CSRQ)'] = conv.df_rst['出生日期(CSRQ)'].apply(lambda e:conv.date2ymdformat(e))
conv.df_rst['入院时间(RYSJ)'] = conv.df_rst['入院时间(RYSJ)'].apply(lambda e:conv.date2ymdformat(e))
conv.df_rst['出院时间(CYSJ)'] = conv.df_rst['出院时间(CYSJ)'].apply(lambda e:conv.date2ymdformat(e))
conv.df_rst['质控日期(ZKRQ)'] = conv.df_rst['质控日期(ZKRQ)'].apply(lambda e:conv.date2ymdformat(e))
conv.setter_set()
conv.diag_with_normal_name()
conv.surg_with_normal_name()
df_rst = conv.df_rst.loc[:,conv.col_order]

xl_out = pd.ExcelWriter(f"output_zb_{datetime.date.today()}.xlsx",engine="xlsxwriter")
df_rst.to_excel(xl_out,'Sheet0',index=False)
xl_out.save()
```

